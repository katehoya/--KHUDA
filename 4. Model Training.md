##Deep Dive는 맨 아래에 있습니다

# 4.1 Linear Regression

기본 모델 : ![image](https://github.com/user-attachments/assets/7fac37d0-04bf-4cae-8f11-29aa41d7361a)  


벡터 형태 : ![image](https://github.com/user-attachments/assets/352ad60f-1cc3-4581-a26a-a5602f2cf3a3)  
Cost Function으로는 MSE를 사용 ![image](https://github.com/user-attachments/assets/a0d0e750-6d47-483d-9f7a-659df0656033)  
==> Cost function을 최소화 하는 parameter를 찾아야 함
  방법 1 : 정규 방정식 이용.&nbsp;&nbsp;&nbsp;&nbsp;![image](https://github.com/user-attachments/assets/0d635ea7-7f7e-4c84-8cc1-505041632948)  
장점 : 간단하다  
단점 : X^T X를 계산하는 게 어렵다. Time Complexity가 O(n^3)나 된다.
  방법 2 : Gradient Descent 이용  

# 4.2 Gradient Descent

Cost function이 작아지도록 theta 수정.  
![image](https://github.com/user-attachments/assets/d0122cb8-bdd9-4fad-89d8-4b58e0ba0f08)  
Step의 크기(Learning Rate) : hyperparameter로써 정해줘야 함.  
Learning rate 너무 작으면 - 수렴 속도가 너무 느려짐  ![image](https://github.com/user-attachments/assets/fe0b7aee-3c3a-4f02-b229-05bbc052d355)  
Learning rate 너무 크면 - minima를 벗어날 수도 있음  ![image](https://github.com/user-attachments/assets/5713010a-70b8-4e20-a3fc-1411027404a6)  

Gradient Descent의 단점 : local minima와 global minima가 불일치 할 경우 global minima를 찾는 것이 복잡해질 수도 있다. 
![image](https://github.com/user-attachments/assets/66bba130-9edc-4df2-97ae-4737bfcb30ab)  
그래서 처음에는 Learning rate를 큰 값으로 설정하고(for Global minima를 찾기 위해) 나중으로 갈 수록 점점 Learning rate를 줄여야 함(for local minima를 찾기 위해.  
그러나 Cost Function으로 MSE를 쓴다면 MSE가 convex function이 되어 global minima == local minima 가 된다.  

minima를 찾아서 가는 법 : ![image](https://github.com/user-attachments/assets/8e488b3c-bcd2-4748-8914-24d56fbb9940)  
![image](https://github.com/user-attachments/assets/44a594da-10b1-4cb2-a540-2772ff14c998)  
![image](https://github.com/user-attachments/assets/8c3dcf79-e3c6-40e5-8bf5-fa5ca66b3ca5)  
![image](https://github.com/user-attachments/assets/1f978df0-9803-487c-bc42-2f89f314d390)  
![image](https://github.com/user-attachments/assets/6edf43a4-c822-4a1e-bf01-a874dd270dfc)  

이렇게 각 step마다 점점 minima를 찾아서 가게 된다.  
각 step의 발걸음을 언제 딛을 것이냐에 따라 Batch Gradient Descent, Stochastic Gradient Descent로 나눌 수 있다.  
Batch : 전체 training set을 훈련하고 난 뒤에 step.  
Stochastic : 각 sample을 훈련하고 난 뒤에 step.  
Mini-batch : 임의의 작은 sample set( named mini-batch)를 훈련하고 난 뒤에 step을 감.  
![image](https://github.com/user-attachments/assets/eabf1004-a06e-445e-beb2-28cfc44fb012)  

![image](https://github.com/user-attachments/assets/53ae6247-80ae-46dc-a977-6804a3aa2175)  


++ Feature Scaling을 해줘야 한다  
![image](https://github.com/user-attachments/assets/1256d3ba-9b07-4d04-b2f4-5c6ff8531701)  

# 4.3 Polynomial Regression  


# 4.4 Learning curve  
Learning curve : Overfitting, Underfitting 여부를 확인할 수 있는 근거가 됨  


![image](https://github.com/user-attachments/assets/1328981a-c339-410f-9555-43dcb8690ec9)  
-> Underfitting이다.  
training set, test set의 차이가 크지 않으므로 overfitting은 아닌데,  
오차가 너무 크기 때문에 underfitting이 의심된다. 또한 training set의 크기가 커져도 오차가 줄어들지 않는 걸 보면 모델의 표현력이 부족하다고 볼 수 있다.

![image](https://github.com/user-attachments/assets/83d8c6fe-697c-49c8-9ab9-189347c51547)  
-> overfitting이다.
training set의 오차가 test보다 너무 낮다.  

# 4.5 Regularization  
MSE에 규제항을 추가함으로써 가중치를 작게 유지.(가중치 감쇠 라고도 한다)  
![image](https://github.com/user-attachments/assets/4d030630-340e-4394-bcc6-294942429c5e)  
람다 : model을 얼마나 많이 규제할 지.  
규제항으로 무엇을 사용할 것인가에 따라 Ridge, Lasso regression 있다.
![image](https://github.com/user-attachments/assets/e6aa8c0e-8456-4309-bde9-e2a24b20b847)  
##  Ridge regression  
![image](https://github.com/user-attachments/assets/2da64275-87af-4c05-b92f-72cc7cd67d26)  
![image](https://github.com/user-attachments/assets/31795d0a-3e04-4c9d-990e-af752fd61327)  
![image](https://github.com/user-attachments/assets/95e626e7-5a2e-41c7-bedc-d41c9479c12b)  
![image](https://github.com/user-attachments/assets/9891a920-c7c3-4af9-b929-39b524bc38cc)  
![image](https://github.com/user-attachments/assets/e056f9cf-b04e-488b-89c6-3500b25c0689)  

## Lasso regression  
![image](https://github.com/user-attachments/assets/29ddcfa8-e9c4-4b13-bfe4-c5ea21b076f8)  
![image](https://github.com/user-attachments/assets/772b022f-249b-4c0b-b4ea-96fd7174ebaf)  
![image](https://github.com/user-attachments/assets/762db6dc-1f16-42ea-b17b-6733b93c1b4b)  
![image](https://github.com/user-attachments/assets/84a152cc-da1a-41c4-a183-3c296f63a862)  

![image](https://github.com/user-attachments/assets/7195a393-e0cb-4a6f-88e3-6d73f744124b)

## Elastic net regression  
Lidge, Lasso를 절충한 모델이다. 일반적으로 가장 좋다  
![image](https://github.com/user-attachments/assets/2c2012dc-4e74-4533-8d8d-8c7486bde166)  
--> 규제항이 단순히 Lidge, Lasso의 그것을 더한 모습.  

## 조기 종료  
별다른 규제항을 추가하지 않고, 단순히 training set, test set 간의 정확도가 차이가 나는 시점(overfitting이 시작하는 시점)에 학습을 중단시킴.  
![image](https://github.com/user-attachments/assets/b957eafa-28b2-4e7b-b1df-59f97b454f92)  

# 4.6 Logistic Regression  
 - Activation function으로서 logistic fuction을 사용하는 것.
 - binary classification에서, sample이 positive class에 속할 확률을 구할 수 있다.  
![image](https://github.com/user-attachments/assets/73bab3be-9f69-4ff9-b764-a127265669ba)  
![image](https://github.com/user-attachments/assets/680d03da-c46d-45ae-9118-0514d6ff18b5)

ex)  ![image](https://github.com/user-attachments/assets/49450324-5b84-4c5a-babc-b62c34c92b58)  
![image](https://github.com/user-attachments/assets/cd9d59eb-39a4-4c51-a510-3affc3d0011f)  

## Softmax Regression   
 - Activation function으로서 softmax function을 사용하는 것.  
 - multiclass classification에서 sample x가 각 class에 속할 확률을 알 수 있다.
![image](https://github.com/user-attachments/assets/b8452701-4655-47cc-99fa-65489f34863c)  
 - 그 중 가장 확률이 높은 class를 선택하는 것이다.  
![image](https://github.com/user-attachments/assets/4be92deb-87e6-4bc7-afc0-5b75d3477f41)

ex)  ![image](https://github.com/user-attachments/assets/37717b94-8902-494b-b55d-4380ec19e824)  


# Deep Dive
## 1. Lidge, Lasso 회귀  
 - 어떤 경우에 릿지 회귀가 유리하며 어떤 경우에 라쏘 회귀가 유리한가?
     Lasso : 가중치가 0이되는 feature가 존재한다. 그래서 선형 회귀에 적용하면 원한는 몇몇 feature만을 선택할 수 있는 효과가 있다.
     Ridge : 한 feature를 완전히 제외한다기 보다는 모든 feature들이 조금씩 다 필요할 때. feature들이 서로 상관관계가 있는 경우

 - 데이터의 크기와 차원이 커질 경우 둘의 성능과 효율성은 어떻게 변화할까?
     Ridge : l2-norm을 사용하기 때문에 차원이 좀 높아져도 효율적으로 regularize할 수 있다. 그러나 모든 feature를 다 사용하기 때문에 계산이 느리다.
     Lasso : 원하는 feature를 선택할 수 있기 때문에 차원이 높아져도 계산이 효율적으로 작동할 가능성이 높다. 그러나 상관관계가 높은 feature들이 있을 경우에는 중요한 데이터가 삭제될 수도 있다.
   
 - 엘라스틱넷은 둘의 어떠한 장점과 특징을 각각 가져가는가?
     둘 다 적합하지 않을 때 엘라스틱넷을 사용한다. 엘라스틱넷은 ridge, lasso의 항을 모두 갖고 있기 때문에 상호보완적으로 사용가능하기 때문이다.
     Lasso의 원하지 않는 feature를 삭제할 수도 있지만 동시에 ridge 항으로 인해 해당 feature가 완전히 사라지지는 않고, 그 가중치가 줄어들어 모든 특성을 유지하되 잠재적인 상관관계를 해치지 않는다.
     
## 2. 미니배치 경사하강법의 배치크기 
- 배치 크기가 모델 학습에 미치는 영향은 무엇일까?
  일단 GPU 메모리의 크기 때문에 너무 큰 배치 사이즈를 넣지 못 할 수도 있다.
  배치 사이즈가 작아지면 업데이트를 자주 하게 되지만 학습 noise가 커진다. 그래서  regularization 효과가 있다
  그러나 너무 작은 배치 사이즈는 오히려 underfitting 위험성이 있다.
  작은 배치 사이즈는 flat minimum(일반화 성능이 좋은 최솟값)을 갖는 경향이 있고 큰 배치 사이즈는 sharp minimum(overfitting)을 잘 찾는 경향이 있다.
- 어떤 경우에 큰 배치가 유리하고 어떤 경우에 작은 배치가 유리한가?
  큰 배치는 수렴 속도가 빠르고, noise에 둔감하고, GPU, TPU의 병렬 연산 이점을 살릴 수 있다는 장점이 있다. 또한 매 UPDATE마다 작은 배치보다 덜 급격히 움직이기 때문에 안정적인 학습이 가능하다.
  작은 배치는 Generalization성능이 좋으며 flat minimum을 찾기 때문에 non-convex 문제를 풀 때 좋다. 또한 실시간 시스템에서 매번 들어오는 데이터를 작은 batch로 학습하는 게 유리할 수도 있다.
- 여러 배치 크기를 일일이 실험해보는 것 없이 효율적으로 최적화된 배치 크기를 찾는 방법은 없을까?
  Baysian Optimization
  hyper parameter(batch size, learning rate..)등을 처음에 몇 개를 test해보고 각 hyper parameter에 대한 정확도를 측정함. 그리고 이를 이용해 hyper parameter와 성능과의 관계를 찾아서 최적의 배치 사이즈를 찾음. -> batch size 찾는 데 비용이 적게 듬, 다양한 hyper parameter에 적용가능
  
## 3. 소프트맥스와 손실 함수
- 손실 함수에는 어떤 것들이 있을까?
  MSE, Binary Cross Entrophy, Categorical Cross Entrophy
- 크로스 엔트로피 손실 함수의 직관적인 해석은?
  정답 클래스에 대한 예측 확률 분포의 -log.
- 왜 소프트맥스와 크로스 엔트로피를 결합하는 것이 최적화에 유리한가?
  Softmax로 확률을 만들고, Cross Entrophy로 측정하면 간결한 미분 형태를 얻어 학습이 빠르고 안정적이며 예측 분포를 실제 정답과 비교할 때 수학적으로도 간단하고 안정적인 gradient를 제공하기 때문


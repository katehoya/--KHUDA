# 5. Support Vector Machine  

## 5-1. 선형 SVM Classifiation
기본 : Large Margin Classification  
 - 클래스 사이에 폭이 가장 넓은 도로를 찾는 것
![image](https://github.com/user-attachments/assets/93e4c855-6979-4f04-9bd7-2c0c0341b69a)
가장 경계에 걸쳐 있는, 분류의 기준이 되는 샘플 : Support Vector  
Supprt Vector 간의 거리 : Margin  

Hard Margin의 단점 : 이상치에 민감하다. 어떤 예외도 있으면 안되기 때문  
![image](https://github.com/user-attachments/assets/d9130e0e-909a-4bab-bcf0-9fd5c3c73649)  

Soft Margin : 약간의 예외를 허용하는 것.  
C : 규제 Hyperparameter  
![image](https://github.com/user-attachments/assets/79781483-50ea-4944-b92b-245c1c6b400e)  

## 5-2. 비선형 SVM Classification  
 - 비선형 dataset에 특성을 추가해서 선형 분류가 가능하게 하는 것.
![image](https://github.com/user-attachments/assets/2d2240b2-ba21-4750-9245-325b49629406)  
![image](https://github.com/user-attachments/assets/cc01512a-bdb7-4c5a-9700-d1b32a1a0c14)   

###5-2.2 유사도 특성  
유사도 함수 : 각 sample이 랜드마크와 얼마나 닮았는 지 측정함으로써 새로운 좌표축을 설정하는 것.  
![image](https://github.com/user-attachments/assets/9a228d24-33df-4524-886d-f99118497e19)  

## 5-3. SVM 회귀(SVR)  
SVM 분류 : 클래스 간의 도로폭이 최대가 되도록  
SVM 회귀 : 도로 안에 가능한 많은 샘플이 들어가도록  
![image](https://github.com/user-attachments/assets/6b3d7cd8-96e9-4c6c-acb0-6fc1286ee6b9)  

## 5-4. SVM이론  
![image](https://github.com/user-attachments/assets/f6bed6fa-2e0f-488a-8c46-2e186a9d606c)  
선형 SVM 분류기로 예측을 하려면 가중치 벡터 W와 bias b를 찾아야 한다.  
![image](https://github.com/user-attachments/assets/0a249d07-9c04-429b-8fb3-21af0da2abe3)  
가중치 벡터 W에 따라 그래프의 기울기(너비)가 바뀌고, 마진도 바뀌는 걸 알 수 있다.  
![image](https://github.com/user-attachments/assets/17808263-cce2-49d7-996b-0f9e61b74232)  
![image](https://github.com/user-attachments/assets/b29ce02e-795b-43ea-a48d-1fb22a530e46)  
![image](https://github.com/user-attachments/assets/9aa8998b-4134-4764-84cf-2b5206a66954)









